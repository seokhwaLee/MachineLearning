{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "from numpy.fft import fft, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./data/train_features.csv')\n",
    "train_labels=pd.read_csv('./data/train_labels.csv')\n",
    "test=pd.read_csv('./data/test_features.csv')\n",
    "\n",
    "submission=pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  가속도, 자이로, (자이로-가속도) 센서값을 에너지로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acc_Energy']=(train['acc_x']**2+train['acc_y']**2+train['acc_z']**2)**(1/2)\n",
    "test['acc_Energy']=(test['acc_x']**2+test['acc_y']**2+test['acc_z']**2)**(1/2)\n",
    "\n",
    "train['gy_Energy']=(train['gy_x']**2+train['gy_y']**2+train['gy_z']**2)**(1/2)\n",
    "test['gy_Energy']=(test['gy_x']**2+test['gy_y']**2+test['gy_z']**2)**(1/2)\n",
    "\n",
    "train['gy_acc_Energy']=((train['gy_x']-train['acc_x'])**2+(train['gy_y']-train['acc_y'])**2+(train['gy_z']-train['acc_z'])**2)**(1/2)\n",
    "test['gy_acc_Energy']=((test['gy_x']-test['acc_x'])**2+(test['gy_y']-test['acc_y'])**2+(test['gy_z']-test['acc_z'])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### id별 데이터는 0.02초마다 측정된 값들이기 때문에 이전 시간 대비 변화량 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.02 \n",
    "def jerk_signal(signal): \n",
    "        return np.array([(signal[i+1]-signal[i])/dt for i in range(len(signal)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [01:20<00:00, 38.60it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dt=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    train_dt.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 782/782 [00:18<00:00, 42.18it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dt=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    test_dt.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 가속도, 자이로 센서값들을 푸리에 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "from numpy.fft import *\n",
    "\n",
    "def fourier_transform_one_signal(t_signal):\n",
    "    complex_f_signal= fftpack.fft(t_signal)\n",
    "    amplitude_f_signal=np.abs(complex_f_signal)\n",
    "    return amplitude_f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat(train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:21<00:00, 145.82it/s]\n"
     ]
    }
   ],
   "source": [
    "fft=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for i in train.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft.append(temp)\n",
    "train=pd.concat(fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.concat(test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 782/782 [00:02<00:00, 275.33it/s]\n"
     ]
    }
   ],
   "source": [
    "fft_t=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for i in test.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft_t.append(temp)\n",
    "test=pd.concat(fft_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard scaling 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=train.columns\n",
    "train_s=train.copy()\n",
    "test_s=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_s.iloc[:,2:]= scaler.fit_transform(train_s.iloc[:,2:])\n",
    "train_sc = pd.DataFrame(data = train_s,columns =col)\n",
    "\n",
    "test_s.iloc[:,2:]= scaler.transform(test_s.iloc[:,2:])\n",
    "test_sc = pd.DataFrame(data = test_s,columns =col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "      <th>acc_Energy</th>\n",
       "      <th>gy_Energy</th>\n",
       "      <th>gy_acc_Energy</th>\n",
       "      <th>acc_x_dt</th>\n",
       "      <th>acc_y_dt</th>\n",
       "      <th>acc_z_dt</th>\n",
       "      <th>gy_x_dt</th>\n",
       "      <th>gy_y_dt</th>\n",
       "      <th>gy_z_dt</th>\n",
       "      <th>acc_Energy_dt</th>\n",
       "      <th>gy_Energy_dt</th>\n",
       "      <th>gy_acc_Energy_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.356382</td>\n",
       "      <td>8.807207</td>\n",
       "      <td>19.465910</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>0.869226</td>\n",
       "      <td>0.150423</td>\n",
       "      <td>0.386070</td>\n",
       "      <td>-0.348596</td>\n",
       "      <td>-0.350907</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054866</td>\n",
       "      <td>0.833464</td>\n",
       "      <td>0.820412</td>\n",
       "      <td>-0.282128</td>\n",
       "      <td>-0.093560</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.606254</td>\n",
       "      <td>-0.322359</td>\n",
       "      <td>-0.325307</td>\n",
       "      <td>0.416836</td>\n",
       "      <td>-0.118821</td>\n",
       "      <td>-0.255054</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>-0.349095</td>\n",
       "      <td>0.377085</td>\n",
       "      <td>0.471582</td>\n",
       "      <td>0.103158</td>\n",
       "      <td>0.100703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024046</td>\n",
       "      <td>0.315921</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>-0.182551</td>\n",
       "      <td>-0.053585</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.675697</td>\n",
       "      <td>-0.273597</td>\n",
       "      <td>-0.275752</td>\n",
       "      <td>0.086405</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>-0.531727</td>\n",
       "      <td>-0.141582</td>\n",
       "      <td>-0.202368</td>\n",
       "      <td>-0.004887</td>\n",
       "      <td>0.148767</td>\n",
       "      <td>0.190810</td>\n",
       "      <td>0.193931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>0.117634</td>\n",
       "      <td>-0.040874</td>\n",
       "      <td>-0.194863</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.644776</td>\n",
       "      <td>-0.170208</td>\n",
       "      <td>-0.174164</td>\n",
       "      <td>-0.058780</td>\n",
       "      <td>-0.213920</td>\n",
       "      <td>0.285459</td>\n",
       "      <td>0.229520</td>\n",
       "      <td>-0.385106</td>\n",
       "      <td>-0.135647</td>\n",
       "      <td>-0.066170</td>\n",
       "      <td>0.403367</td>\n",
       "      <td>0.396441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151477</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.317742</td>\n",
       "      <td>-0.350724</td>\n",
       "      <td>0.494539</td>\n",
       "      <td>0.154354</td>\n",
       "      <td>0.650073</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>-0.128402</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.259227</td>\n",
       "      <td>-0.055206</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>-0.174917</td>\n",
       "      <td>-0.028047</td>\n",
       "      <td>0.011395</td>\n",
       "      <td>0.178784</td>\n",
       "      <td>0.179169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>0.365037</td>\n",
       "      <td>0.011656</td>\n",
       "      <td>0.845701</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>0.350395</td>\n",
       "      <td>0.112282</td>\n",
       "      <td>-0.155342</td>\n",
       "      <td>0.619348</td>\n",
       "      <td>0.613624</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.119409</td>\n",
       "      <td>-0.108728</td>\n",
       "      <td>-0.027804</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>-0.110914</td>\n",
       "      <td>0.055676</td>\n",
       "      <td>0.055911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>10.220817</td>\n",
       "      <td>5.476964</td>\n",
       "      <td>7.441373</td>\n",
       "      <td>3.605246</td>\n",
       "      <td>16.530576</td>\n",
       "      <td>11.843241</td>\n",
       "      <td>-0.178947</td>\n",
       "      <td>0.604411</td>\n",
       "      <td>0.599017</td>\n",
       "      <td>0.150658</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.265559</td>\n",
       "      <td>-0.027936</td>\n",
       "      <td>0.090560</td>\n",
       "      <td>-0.018412</td>\n",
       "      <td>-0.050501</td>\n",
       "      <td>-0.057051</td>\n",
       "      <td>-0.055782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>0.386337</td>\n",
       "      <td>0.177768</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>-0.192468</td>\n",
       "      <td>-0.033904</td>\n",
       "      <td>-0.227861</td>\n",
       "      <td>-0.166013</td>\n",
       "      <td>0.591351</td>\n",
       "      <td>0.586497</td>\n",
       "      <td>0.093524</td>\n",
       "      <td>-0.049283</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.123264</td>\n",
       "      <td>-0.152712</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>-0.049754</td>\n",
       "      <td>-0.047662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>0.728823</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.350745</td>\n",
       "      <td>0.136284</td>\n",
       "      <td>1.281790</td>\n",
       "      <td>0.403540</td>\n",
       "      <td>-0.185719</td>\n",
       "      <td>0.591201</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.174681</td>\n",
       "      <td>-0.096564</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>-0.014412</td>\n",
       "      <td>-0.049662</td>\n",
       "      <td>-0.042152</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>0.886204</td>\n",
       "      <td>0.075614</td>\n",
       "      <td>1.107553</td>\n",
       "      <td>-0.182228</td>\n",
       "      <td>0.894062</td>\n",
       "      <td>0.311408</td>\n",
       "      <td>-0.224456</td>\n",
       "      <td>0.592772</td>\n",
       "      <td>0.588427</td>\n",
       "      <td>0.266539</td>\n",
       "      <td>-0.107081</td>\n",
       "      <td>0.079654</td>\n",
       "      <td>0.207388</td>\n",
       "      <td>-0.042034</td>\n",
       "      <td>-0.022996</td>\n",
       "      <td>-0.082907</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.008208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time      acc_x     acc_y      acc_z      gy_x       gy_y  \\\n",
       "0           0     0  27.356382  8.807207  19.465910  0.376992   0.869226   \n",
       "1           0     1  -0.054866  0.833464   0.820412 -0.282128  -0.093560   \n",
       "2           0     2   0.024046  0.315921   0.081086 -0.182551  -0.053585   \n",
       "3           0     3   0.065632  0.117634  -0.040874 -0.194863   0.154242   \n",
       "4           0     4   0.151477  0.300751   0.317742 -0.350724   0.494539   \n",
       "...       ...   ...        ...       ...        ...       ...        ...   \n",
       "1874995  3124   595   0.365037  0.011656   0.845701  0.080839   0.350395   \n",
       "1874996  3124   596  10.220817  5.476964   7.441373  3.605246  16.530576   \n",
       "1874997  3124   597   0.386337  0.177768  -0.080193 -0.192468  -0.033904   \n",
       "1874998  3124   598   0.728823  0.014037   0.350745  0.136284   1.281790   \n",
       "1874999  3124   599   0.886204  0.075614   1.107553 -0.182228   0.894062   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0         0.150423    0.386070  -0.348596      -0.350907  0.000027  0.000298   \n",
       "1         0.011266    0.606254  -0.322359      -0.325307  0.416836 -0.118821   \n",
       "2        -0.003708    0.675697  -0.273597      -0.275752  0.086405  0.023750   \n",
       "3         0.005408    0.644776  -0.170208      -0.174164 -0.058780 -0.213920   \n",
       "4         0.154354    0.650073  -0.124536      -0.128402  0.039823  0.259227   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995   0.112282   -0.155342   0.619348       0.613624  0.151679  0.037205   \n",
       "1874996  11.843241   -0.178947   0.604411       0.599017  0.150658 -0.000363   \n",
       "1874997  -0.227861   -0.166013   0.591351       0.586497  0.093524 -0.049283   \n",
       "1874998   0.403540   -0.185719   0.591201       0.586592  0.174681 -0.096564   \n",
       "1874999   0.311408   -0.224456   0.592772       0.588427  0.266539 -0.107081   \n",
       "\n",
       "         acc_z_dt   gy_x_dt   gy_y_dt   gy_z_dt  acc_Energy_dt  gy_Energy_dt  \\\n",
       "0       -0.000433  0.000347  0.000373  0.000273       0.000050      0.001067   \n",
       "1       -0.255054  0.032738 -0.349095  0.377085       0.471582      0.103158   \n",
       "2       -0.531727 -0.141582 -0.202368 -0.004887       0.148767      0.190810   \n",
       "3        0.285459  0.229520 -0.385106 -0.135647      -0.066170      0.403367   \n",
       "4       -0.055206  0.057320 -0.174917 -0.028047       0.011395      0.178784   \n",
       "...           ...       ...       ...       ...            ...           ...   \n",
       "1874995  0.119409 -0.108728 -0.027804 -0.009085      -0.110914      0.055676   \n",
       "1874996  0.265559 -0.027936  0.090560 -0.018412      -0.050501     -0.057051   \n",
       "1874997  0.260884  0.082744  0.123264 -0.152712       0.027749     -0.049754   \n",
       "1874998  0.071332  0.153722 -0.014412 -0.049662      -0.042152      0.000486   \n",
       "1874999  0.079654  0.207388 -0.042034 -0.022996      -0.082907      0.007180   \n",
       "\n",
       "         gy_acc_Energy_dt  \n",
       "0                0.001067  \n",
       "1                0.100703  \n",
       "2                0.193931  \n",
       "3                0.396441  \n",
       "4                0.179169  \n",
       "...                   ...  \n",
       "1874995          0.055911  \n",
       "1874996         -0.055782  \n",
       "1874997         -0.047662  \n",
       "1874998          0.001437  \n",
       "1874999          0.008208  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델링\n",
    "\n",
    "+ CNN, LSTM, CNN+LSTM 등 여러 구조 적용해보다가 CNN에서 Flatten 없이 Global average pooling 한 구조가 가장 성능이 좋아 채택했습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.13.0-cp38-cp38-win_amd64.whl (615 kB)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.12.1-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.13.0 typeguard-2.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import optimizers,datasets,layers,models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Bidirectional,Dropout,Activation,Flatten\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 600, 18)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(train_sc.iloc[:,2:]).reshape(3125, 600, -1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 61)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_labels['label'].values\n",
    "y = tf.keras.utils.to_categorical(train_labels['label']) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_shape, classes):\n",
    "    seed(2021)\n",
    "    tf.random.set_seed(2021)\n",
    "    \n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    conv1 = keras.layers.Conv1D(filters=128, kernel_size=9, padding='same')(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "    conv1 = keras.layers.Dropout(rate=0.3)(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=256, kernel_size=6, padding='same')(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.Activation('relu')(conv2)\n",
    "    conv2 = keras.layers.Dropout(rate=0.4)(conv2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv1D(128, kernel_size=3,padding='same')(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.Activation('relu')(conv3)\n",
    "    conv3 = keras.layers.Dropout(rate=0.5)(conv3)\n",
    "    \n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "    \n",
    "    output_layer = keras.layers.Dense(classes, activation='softmax')(gap)\n",
    "    \n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(), \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10-fold StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Fold_1--------------------\n",
      "Epoch 1/100\n",
      " 8/44 [====>.........................] - ETA: 1:25 - loss: 3.8986 - accuracy: 0.2363"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-6d0fc1e7772a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"Fold_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"-\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m61\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     history = model.fit(X[train], y[train], epochs = 100, validation_data= (X[validation], y[validation]), \n\u001b[0m\u001b[0;32m     14\u001b[0m                         verbose=1,batch_size=64,callbacks=[es,mc,reLR])\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./model_kf/cv_study{i + 1}.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 2021, shuffle = True)\n",
    "reLR = ReduceLROnPlateau(patience = 4,verbose = 1,factor = 0.5) \n",
    "es =EarlyStopping(monitor='val_loss', patience=8, mode='min')\n",
    "\n",
    "accuracy = []\n",
    "losss=[]\n",
    "models=[]\n",
    "\n",
    "for i, (train, validation) in enumerate(skf.split(X, y.argmax(1))) :\n",
    "    mc = ModelCheckpoint(f'./cv_study{i + 1}.h5',save_best_only=True, verbose=0, monitor = 'val_loss', mode = 'min', save_weights_only=True)\n",
    "    print(\"-\" * 20 +\"Fold_\"+str(i+1)+ \"-\" * 20)\n",
    "    model = cnn_model((600,18),61)\n",
    "    history = model.fit(X[train], y[train], epochs = 100, validation_data= (X[validation], y[validation]), \n",
    "                        verbose=1,batch_size=64,callbacks=[es,mc,reLR])\n",
    "    model.load_weights(f'./model_kf/cv_study{i + 1}.h5')\n",
    "    \n",
    "    k_accuracy = '%.4f' % (model.evaluate(X[validation], y[validation])[1])\n",
    "    k_loss = '%.4f' % (model.evaluate(X[validation], y[validation])[0])\n",
    "    \n",
    "    accuracy.append(k_accuracy)\n",
    "    losss.append(k_loss)\n",
    "    models.append(model)\n",
    "\n",
    "print('\\nK-fold cross validation Auc: {}'.format(accuracy))\n",
    "print('\\nK-fold cross validation loss: {}'.format(losss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 성능 확인 및 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8528\n",
      "\n",
      "0.48506\n"
     ]
    }
   ],
   "source": [
    "print(sum([float(i) for i in accuracy])/10)\n",
    "print()\n",
    "print(sum([float(i) for i in losss])/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X=np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.11362115e-05, 2.25996450e-06, 2.11680984e-07, ...,\n",
       "        6.39248919e-03, 1.50766409e-05, 3.40101496e-06],\n",
       "       [4.13231173e-04, 1.99007154e-05, 1.22563812e-04, ...,\n",
       "        8.93750075e-06, 2.06302539e-05, 1.22722922e-05],\n",
       "       [1.86802447e-03, 3.26019563e-02, 1.62000761e-05, ...,\n",
       "        8.92708835e-04, 1.20446784e-02, 2.22884724e-03],\n",
       "       ...,\n",
       "       [4.16979339e-04, 3.25313522e-06, 1.09946477e-05, ...,\n",
       "        1.80470997e-05, 1.36069389e-06, 7.54901499e-04],\n",
       "       [3.85870408e-06, 8.71700991e-04, 9.34987668e-07, ...,\n",
       "        1.06083007e-07, 1.25161705e-05, 4.91666885e-09],\n",
       "       [9.32284092e-05, 4.08958658e-06, 1.09709674e-06, ...,\n",
       "        9.87853055e-05, 9.04675460e-07, 1.53993984e-04]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict(test_X)\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.116810e-07</td>\n",
       "      <td>4.708937e-08</td>\n",
       "      <td>1.865657e-04</td>\n",
       "      <td>1.124369e-07</td>\n",
       "      <td>3.247155e-04</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.424222e-07</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.100756</td>\n",
       "      <td>4.794668e-01</td>\n",
       "      <td>1.128225e-04</td>\n",
       "      <td>3.902865e-01</td>\n",
       "      <td>2.294270e-03</td>\n",
       "      <td>3.994864e-06</td>\n",
       "      <td>2.203607e-06</td>\n",
       "      <td>7.347716e-07</td>\n",
       "      <td>4.205005e-07</td>\n",
       "      <td>9.210566e-08</td>\n",
       "      <td>3.008443e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>7.120603e-07</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>9.638647e-04</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.705775e-05</td>\n",
       "      <td>2.177705e-07</td>\n",
       "      <td>6.212062e-09</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>3.137485e-05</td>\n",
       "      <td>8.554223e-04</td>\n",
       "      <td>3.529570e-05</td>\n",
       "      <td>1.155294e-07</td>\n",
       "      <td>3.284435e-06</td>\n",
       "      <td>2.174506e-06</td>\n",
       "      <td>3.665759e-08</td>\n",
       "      <td>4.478506e-04</td>\n",
       "      <td>4.650679e-04</td>\n",
       "      <td>1.211206e-05</td>\n",
       "      <td>2.320302e-06</td>\n",
       "      <td>1.255611e-07</td>\n",
       "      <td>2.459125e-07</td>\n",
       "      <td>8.899527e-10</td>\n",
       "      <td>6.392489e-03</td>\n",
       "      <td>1.507664e-05</td>\n",
       "      <td>3.401015e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1.225638e-04</td>\n",
       "      <td>1.330648e-03</td>\n",
       "      <td>5.290742e-05</td>\n",
       "      <td>6.115026e-04</td>\n",
       "      <td>2.825133e-06</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>7.107466e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.578770e-06</td>\n",
       "      <td>1.445539e-08</td>\n",
       "      <td>2.135061e-06</td>\n",
       "      <td>1.027968e-06</td>\n",
       "      <td>2.940293e-04</td>\n",
       "      <td>2.704988e-05</td>\n",
       "      <td>1.144425e-05</td>\n",
       "      <td>2.083481e-05</td>\n",
       "      <td>4.048173e-06</td>\n",
       "      <td>2.643172e-05</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>2.340468e-03</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>4.793614e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.656085e-08</td>\n",
       "      <td>4.648645e-04</td>\n",
       "      <td>3.747970e-04</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.712846e-06</td>\n",
       "      <td>4.472250e-06</td>\n",
       "      <td>8.808629e-06</td>\n",
       "      <td>1.643756e-05</td>\n",
       "      <td>1.192999e-04</td>\n",
       "      <td>2.324675e-03</td>\n",
       "      <td>6.748711e-04</td>\n",
       "      <td>7.841913e-06</td>\n",
       "      <td>1.797475e-08</td>\n",
       "      <td>9.208373e-05</td>\n",
       "      <td>1.928369e-04</td>\n",
       "      <td>1.234607e-04</td>\n",
       "      <td>4.037772e-06</td>\n",
       "      <td>1.639472e-04</td>\n",
       "      <td>8.937501e-06</td>\n",
       "      <td>2.063025e-05</td>\n",
       "      <td>1.227229e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>1.620008e-05</td>\n",
       "      <td>1.283705e-05</td>\n",
       "      <td>3.405659e-05</td>\n",
       "      <td>6.504179e-04</td>\n",
       "      <td>1.054489e-01</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>1.890009e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>4.135342e-04</td>\n",
       "      <td>3.376489e-05</td>\n",
       "      <td>2.495863e-03</td>\n",
       "      <td>1.967650e-02</td>\n",
       "      <td>8.969253e-04</td>\n",
       "      <td>1.574834e-04</td>\n",
       "      <td>1.690211e-04</td>\n",
       "      <td>4.927005e-05</td>\n",
       "      <td>2.873521e-04</td>\n",
       "      <td>2.336423e-04</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>5.826922e-07</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>4.887589e-02</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>3.705476e-04</td>\n",
       "      <td>2.303389e-04</td>\n",
       "      <td>1.743668e-04</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>0.195926</td>\n",
       "      <td>7.786207e-03</td>\n",
       "      <td>4.333588e-01</td>\n",
       "      <td>2.320479e-04</td>\n",
       "      <td>2.547552e-03</td>\n",
       "      <td>2.427308e-03</td>\n",
       "      <td>4.264420e-03</td>\n",
       "      <td>3.207233e-06</td>\n",
       "      <td>4.141561e-05</td>\n",
       "      <td>2.466323e-05</td>\n",
       "      <td>1.434178e-06</td>\n",
       "      <td>8.685702e-04</td>\n",
       "      <td>1.100743e-06</td>\n",
       "      <td>3.044588e-03</td>\n",
       "      <td>6.567472e-08</td>\n",
       "      <td>8.927088e-04</td>\n",
       "      <td>1.204468e-02</td>\n",
       "      <td>2.228847e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.345231e-05</td>\n",
       "      <td>1.176274e-04</td>\n",
       "      <td>1.757207e-05</td>\n",
       "      <td>1.440693e-04</td>\n",
       "      <td>5.411918e-06</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.369785e-03</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>1.052319e-04</td>\n",
       "      <td>2.757647e-06</td>\n",
       "      <td>2.441343e-06</td>\n",
       "      <td>1.215714e-05</td>\n",
       "      <td>7.255679e-04</td>\n",
       "      <td>1.776193e-06</td>\n",
       "      <td>4.248767e-06</td>\n",
       "      <td>1.051885e-05</td>\n",
       "      <td>8.755162e-06</td>\n",
       "      <td>5.609869e-06</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1.119547e-04</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>2.999797e-06</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.534645e-06</td>\n",
       "      <td>1.452966e-05</td>\n",
       "      <td>1.911514e-05</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2.528368e-05</td>\n",
       "      <td>4.395631e-05</td>\n",
       "      <td>1.043876e-05</td>\n",
       "      <td>6.607959e-05</td>\n",
       "      <td>3.738505e-03</td>\n",
       "      <td>8.310549e-03</td>\n",
       "      <td>6.330538e-04</td>\n",
       "      <td>1.585062e-04</td>\n",
       "      <td>5.253386e-06</td>\n",
       "      <td>2.855355e-05</td>\n",
       "      <td>1.086101e-04</td>\n",
       "      <td>3.191976e-05</td>\n",
       "      <td>3.284602e-06</td>\n",
       "      <td>5.761672e-05</td>\n",
       "      <td>2.509627e-05</td>\n",
       "      <td>5.781790e-06</td>\n",
       "      <td>7.223898e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>2.595292e-06</td>\n",
       "      <td>2.950884e-04</td>\n",
       "      <td>2.631509e-04</td>\n",
       "      <td>2.281394e-05</td>\n",
       "      <td>7.910090e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.282780e-05</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6.662969e-06</td>\n",
       "      <td>1.271762e-06</td>\n",
       "      <td>3.870370e-07</td>\n",
       "      <td>1.917479e-05</td>\n",
       "      <td>4.299077e-04</td>\n",
       "      <td>9.659639e-06</td>\n",
       "      <td>2.665155e-06</td>\n",
       "      <td>5.571738e-05</td>\n",
       "      <td>2.121639e-06</td>\n",
       "      <td>4.022555e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.395142e-04</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.269365e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.161713e-06</td>\n",
       "      <td>6.367538e-07</td>\n",
       "      <td>5.421267e-06</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>8.105874e-08</td>\n",
       "      <td>1.194872e-06</td>\n",
       "      <td>3.231482e-06</td>\n",
       "      <td>9.941075e-07</td>\n",
       "      <td>3.176446e-04</td>\n",
       "      <td>9.502537e-04</td>\n",
       "      <td>5.820632e-04</td>\n",
       "      <td>5.014890e-06</td>\n",
       "      <td>8.111192e-07</td>\n",
       "      <td>1.425431e-05</td>\n",
       "      <td>2.082707e-06</td>\n",
       "      <td>2.616074e-06</td>\n",
       "      <td>4.458506e-07</td>\n",
       "      <td>2.302143e-03</td>\n",
       "      <td>8.492467e-05</td>\n",
       "      <td>2.439178e-06</td>\n",
       "      <td>3.807932e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>3902</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2.692790e-07</td>\n",
       "      <td>1.392818e-04</td>\n",
       "      <td>3.632546e-04</td>\n",
       "      <td>3.666391e-05</td>\n",
       "      <td>2.516073e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.034942e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.608847e-07</td>\n",
       "      <td>8.443988e-08</td>\n",
       "      <td>4.424959e-08</td>\n",
       "      <td>3.241649e-06</td>\n",
       "      <td>5.664256e-04</td>\n",
       "      <td>1.966830e-05</td>\n",
       "      <td>4.358430e-06</td>\n",
       "      <td>1.377685e-04</td>\n",
       "      <td>1.753900e-06</td>\n",
       "      <td>9.672356e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.599161e-04</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.128838e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.651635e-07</td>\n",
       "      <td>1.488061e-06</td>\n",
       "      <td>1.090116e-05</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.845261e-08</td>\n",
       "      <td>5.673692e-07</td>\n",
       "      <td>2.185301e-06</td>\n",
       "      <td>7.444148e-07</td>\n",
       "      <td>2.017738e-04</td>\n",
       "      <td>3.374573e-04</td>\n",
       "      <td>1.702022e-03</td>\n",
       "      <td>2.183509e-07</td>\n",
       "      <td>3.351120e-08</td>\n",
       "      <td>2.855817e-06</td>\n",
       "      <td>4.701814e-07</td>\n",
       "      <td>2.122393e-07</td>\n",
       "      <td>2.414436e-07</td>\n",
       "      <td>1.602291e-02</td>\n",
       "      <td>2.339808e-05</td>\n",
       "      <td>2.259146e-06</td>\n",
       "      <td>5.595793e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3903</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.418103e-06</td>\n",
       "      <td>2.474411e-04</td>\n",
       "      <td>7.793277e-05</td>\n",
       "      <td>3.450090e-05</td>\n",
       "      <td>3.203852e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.091073e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.682169e-07</td>\n",
       "      <td>1.466343e-08</td>\n",
       "      <td>1.076064e-07</td>\n",
       "      <td>2.007611e-07</td>\n",
       "      <td>1.504268e-04</td>\n",
       "      <td>3.400251e-05</td>\n",
       "      <td>3.794539e-06</td>\n",
       "      <td>1.547392e-04</td>\n",
       "      <td>1.618792e-06</td>\n",
       "      <td>2.004600e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.284377e-03</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>7.070109e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.374649e-08</td>\n",
       "      <td>1.038312e-05</td>\n",
       "      <td>3.036143e-05</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.591797e-08</td>\n",
       "      <td>4.240455e-07</td>\n",
       "      <td>1.551022e-06</td>\n",
       "      <td>1.363590e-07</td>\n",
       "      <td>1.432590e-05</td>\n",
       "      <td>1.126615e-04</td>\n",
       "      <td>8.413609e-05</td>\n",
       "      <td>4.325434e-07</td>\n",
       "      <td>7.853837e-09</td>\n",
       "      <td>1.182301e-05</td>\n",
       "      <td>1.135056e-06</td>\n",
       "      <td>1.329223e-06</td>\n",
       "      <td>6.008780e-07</td>\n",
       "      <td>3.952625e-03</td>\n",
       "      <td>5.511012e-06</td>\n",
       "      <td>6.515145e-07</td>\n",
       "      <td>3.573783e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>3904</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.099465e-05</td>\n",
       "      <td>9.337877e-05</td>\n",
       "      <td>1.634578e-05</td>\n",
       "      <td>8.988440e-05</td>\n",
       "      <td>1.229814e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2.575660e-05</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>7.194992e-06</td>\n",
       "      <td>3.232979e-07</td>\n",
       "      <td>5.068840e-07</td>\n",
       "      <td>7.551430e-06</td>\n",
       "      <td>1.616150e-04</td>\n",
       "      <td>8.896222e-07</td>\n",
       "      <td>4.917642e-07</td>\n",
       "      <td>3.038611e-06</td>\n",
       "      <td>8.085279e-07</td>\n",
       "      <td>4.941950e-06</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.765404e-04</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>4.938819e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.427270e-07</td>\n",
       "      <td>2.785574e-06</td>\n",
       "      <td>5.802608e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>8.832764e-07</td>\n",
       "      <td>4.378901e-06</td>\n",
       "      <td>1.285613e-06</td>\n",
       "      <td>8.524936e-06</td>\n",
       "      <td>4.783742e-04</td>\n",
       "      <td>2.380906e-03</td>\n",
       "      <td>1.889450e-04</td>\n",
       "      <td>1.027952e-05</td>\n",
       "      <td>3.110814e-07</td>\n",
       "      <td>1.133624e-05</td>\n",
       "      <td>1.826907e-05</td>\n",
       "      <td>1.181306e-05</td>\n",
       "      <td>3.889178e-07</td>\n",
       "      <td>7.185910e-05</td>\n",
       "      <td>1.804710e-05</td>\n",
       "      <td>1.360694e-06</td>\n",
       "      <td>7.549015e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3905</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>9.349877e-07</td>\n",
       "      <td>2.897043e-09</td>\n",
       "      <td>1.360930e-08</td>\n",
       "      <td>2.737833e-08</td>\n",
       "      <td>1.765427e-02</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.666289e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.614539e-05</td>\n",
       "      <td>3.251577e-09</td>\n",
       "      <td>2.272466e-04</td>\n",
       "      <td>7.495165e-08</td>\n",
       "      <td>4.059368e-07</td>\n",
       "      <td>1.741021e-05</td>\n",
       "      <td>4.617530e-07</td>\n",
       "      <td>1.403474e-09</td>\n",
       "      <td>3.055238e-08</td>\n",
       "      <td>4.119734e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.097873e-09</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>9.801980e-01</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>3.178972e-07</td>\n",
       "      <td>1.237006e-05</td>\n",
       "      <td>4.006409e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.805889e-05</td>\n",
       "      <td>3.204079e-04</td>\n",
       "      <td>2.950669e-07</td>\n",
       "      <td>4.707098e-04</td>\n",
       "      <td>5.880752e-07</td>\n",
       "      <td>8.497389e-07</td>\n",
       "      <td>5.535009e-10</td>\n",
       "      <td>4.641344e-07</td>\n",
       "      <td>5.805668e-09</td>\n",
       "      <td>7.169170e-09</td>\n",
       "      <td>2.958758e-05</td>\n",
       "      <td>7.718703e-08</td>\n",
       "      <td>1.964780e-06</td>\n",
       "      <td>6.251173e-12</td>\n",
       "      <td>1.060830e-07</td>\n",
       "      <td>1.251617e-05</td>\n",
       "      <td>4.916669e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>3906</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.097097e-06</td>\n",
       "      <td>1.333163e-04</td>\n",
       "      <td>3.200663e-05</td>\n",
       "      <td>2.775637e-05</td>\n",
       "      <td>9.644702e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.585497e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.416702e-07</td>\n",
       "      <td>6.410163e-08</td>\n",
       "      <td>1.649266e-07</td>\n",
       "      <td>4.274219e-06</td>\n",
       "      <td>4.257003e-05</td>\n",
       "      <td>8.205339e-06</td>\n",
       "      <td>7.160952e-07</td>\n",
       "      <td>1.318424e-05</td>\n",
       "      <td>4.357608e-07</td>\n",
       "      <td>7.028999e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>7.395596e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.079032e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.189728e-08</td>\n",
       "      <td>4.557222e-06</td>\n",
       "      <td>2.222234e-05</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.976022e-08</td>\n",
       "      <td>8.475187e-07</td>\n",
       "      <td>1.047357e-06</td>\n",
       "      <td>1.614747e-07</td>\n",
       "      <td>2.474583e-05</td>\n",
       "      <td>1.472671e-04</td>\n",
       "      <td>8.589283e-05</td>\n",
       "      <td>1.351910e-07</td>\n",
       "      <td>1.652482e-08</td>\n",
       "      <td>2.854900e-06</td>\n",
       "      <td>9.722719e-07</td>\n",
       "      <td>3.358905e-07</td>\n",
       "      <td>1.054960e-07</td>\n",
       "      <td>2.254390e-03</td>\n",
       "      <td>9.878531e-05</td>\n",
       "      <td>9.046755e-07</td>\n",
       "      <td>1.539940e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         0         1             2             3             4  \\\n",
       "0    3125  0.000011  0.000002  2.116810e-07  4.708937e-08  1.865657e-04   \n",
       "1    3126  0.000413  0.000020  1.225638e-04  1.330648e-03  5.290742e-05   \n",
       "2    3127  0.001868  0.032602  1.620008e-05  1.283705e-05  3.405659e-05   \n",
       "3    3128  0.000691  0.000010  3.345231e-05  1.176274e-04  1.757207e-05   \n",
       "4    3129  0.004222  0.000031  2.595292e-06  2.950884e-04  2.631509e-04   \n",
       "..    ...       ...       ...           ...           ...           ...   \n",
       "777  3902  0.007722  0.000045  2.692790e-07  1.392818e-04  3.632546e-04   \n",
       "778  3903  0.000128  0.000006  2.418103e-06  2.474411e-04  7.793277e-05   \n",
       "779  3904  0.000417  0.000003  1.099465e-05  9.337877e-05  1.634578e-05   \n",
       "780  3905  0.000004  0.000872  9.349877e-07  2.897043e-09  1.360930e-08   \n",
       "781  3906  0.000093  0.000004  1.097097e-06  1.333163e-04  3.200663e-05   \n",
       "\n",
       "                5             6         7             8         9        10  \\\n",
       "0    1.124369e-07  3.247155e-04  0.000002  1.424222e-07  0.005938  0.100756   \n",
       "1    6.115026e-04  2.825133e-06  0.000066  7.107466e-06  0.000011  0.000024   \n",
       "2    6.504179e-04  1.054489e-01  0.000152  1.890009e-05  0.000041  0.002011   \n",
       "3    1.440693e-04  5.411918e-06  0.000118  1.369785e-03  0.000056  0.000156   \n",
       "4    2.281394e-05  7.910090e-07  0.000003  2.282780e-05  0.000076  0.000025   \n",
       "..            ...           ...       ...           ...       ...       ...   \n",
       "777  3.666391e-05  2.516073e-07  0.000004  5.034942e-05  0.000009  0.000006   \n",
       "778  3.450090e-05  3.203852e-08  0.000003  1.091073e-06  0.000002  0.000001   \n",
       "779  8.988440e-05  1.229814e-06  0.000017  2.575660e-05  0.000022  0.000035   \n",
       "780  2.737833e-08  1.765427e-02  0.000002  1.666289e-08  0.000002  0.000002   \n",
       "781  2.775637e-05  9.644702e-08  0.000002  2.585497e-07  0.000002  0.000010   \n",
       "\n",
       "               11            12            13            14            15  \\\n",
       "0    4.794668e-01  1.128225e-04  3.902865e-01  2.294270e-03  3.994864e-06   \n",
       "1    1.578770e-06  1.445539e-08  2.135061e-06  1.027968e-06  2.940293e-04   \n",
       "2    4.135342e-04  3.376489e-05  2.495863e-03  1.967650e-02  8.969253e-04   \n",
       "3    1.052319e-04  2.757647e-06  2.441343e-06  1.215714e-05  7.255679e-04   \n",
       "4    6.662969e-06  1.271762e-06  3.870370e-07  1.917479e-05  4.299077e-04   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  5.608847e-07  8.443988e-08  4.424959e-08  3.241649e-06  5.664256e-04   \n",
       "778  2.682169e-07  1.466343e-08  1.076064e-07  2.007611e-07  1.504268e-04   \n",
       "779  7.194992e-06  3.232979e-07  5.068840e-07  7.551430e-06  1.616150e-04   \n",
       "780  1.614539e-05  3.251577e-09  2.272466e-04  7.495165e-08  4.059368e-07   \n",
       "781  3.416702e-07  6.410163e-08  1.649266e-07  4.274219e-06  4.257003e-05   \n",
       "\n",
       "               16            17            18            19            20  \\\n",
       "0    2.203607e-06  7.347716e-07  4.205005e-07  9.210566e-08  3.008443e-05   \n",
       "1    2.704988e-05  1.144425e-05  2.083481e-05  4.048173e-06  2.643172e-05   \n",
       "2    1.574834e-04  1.690211e-04  4.927005e-05  2.873521e-04  2.336423e-04   \n",
       "3    1.776193e-06  4.248767e-06  1.051885e-05  8.755162e-06  5.609869e-06   \n",
       "4    9.659639e-06  2.665155e-06  5.571738e-05  2.121639e-06  4.022555e-06   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  1.966830e-05  4.358430e-06  1.377685e-04  1.753900e-06  9.672356e-07   \n",
       "778  3.400251e-05  3.794539e-06  1.547392e-04  1.618792e-06  2.004600e-06   \n",
       "779  8.896222e-07  4.917642e-07  3.038611e-06  8.085279e-07  4.941950e-06   \n",
       "780  1.741021e-05  4.617530e-07  1.403474e-09  3.055238e-08  4.119734e-07   \n",
       "781  8.205339e-06  7.160952e-07  1.318424e-05  4.357608e-07  7.028999e-07   \n",
       "\n",
       "           21            22        23  ...        36            37        38  \\\n",
       "0    0.000004  7.120603e-07  0.005244  ...  0.001091  9.638647e-04  0.000089   \n",
       "1    0.000180  2.340468e-03  0.000217  ...  0.000310  4.793614e-06  0.000002   \n",
       "2    0.000258  5.826922e-07  0.000569  ...  0.000390  4.887589e-02  0.006375   \n",
       "3    0.000086  1.119547e-04  0.000133  ...  0.000285  2.999797e-06  0.000039   \n",
       "4    0.000007  3.395142e-04  0.000008  ...  0.000016  4.269365e-07  0.000011   \n",
       "..        ...           ...       ...  ...       ...           ...       ...   \n",
       "777  0.000002  2.599161e-04  0.000001  ...  0.000004  1.128838e-07  0.000002   \n",
       "778  0.000002  1.284377e-03  0.000007  ...  0.000003  7.070109e-08  0.000002   \n",
       "779  0.000040  1.765404e-04  0.000032  ...  0.000110  4.938819e-07  0.000003   \n",
       "780  0.000003  1.097873e-09  0.000007  ...  0.000006  9.801980e-01  0.000001   \n",
       "781  0.000001  7.395596e-04  0.000014  ...  0.000004  9.079032e-08  0.000003   \n",
       "\n",
       "               39            40            41        42        43  \\\n",
       "0    1.705775e-05  2.177705e-07  6.212062e-09  0.000386  0.000093   \n",
       "1    3.656085e-08  4.648645e-04  3.747970e-04  0.000015  0.000007   \n",
       "2    3.705476e-04  2.303389e-04  1.743668e-04  0.063292  0.195926   \n",
       "3    1.534645e-06  1.452966e-05  1.911514e-05  0.000014  0.000024   \n",
       "4    5.161713e-06  6.367538e-07  5.421267e-06  0.000096  0.000048   \n",
       "..            ...           ...           ...       ...       ...   \n",
       "777  2.651635e-07  1.488061e-06  1.090116e-05  0.000015  0.000004   \n",
       "778  2.374649e-08  1.038312e-05  3.036143e-05  0.000024  0.000007   \n",
       "779  5.427270e-07  2.785574e-06  5.802608e-06  0.000009  0.000012   \n",
       "780  3.178972e-07  1.237006e-05  4.006409e-08  0.000007  0.000009   \n",
       "781  2.189728e-08  4.557222e-06  2.222234e-05  0.000060  0.000014   \n",
       "\n",
       "               44            45            46            47            48  \\\n",
       "0    3.137485e-05  8.554223e-04  3.529570e-05  1.155294e-07  3.284435e-06   \n",
       "1    1.712846e-06  4.472250e-06  8.808629e-06  1.643756e-05  1.192999e-04   \n",
       "2    7.786207e-03  4.333588e-01  2.320479e-04  2.547552e-03  2.427308e-03   \n",
       "3    2.528368e-05  4.395631e-05  1.043876e-05  6.607959e-05  3.738505e-03   \n",
       "4    8.105874e-08  1.194872e-06  3.231482e-06  9.941075e-07  3.176446e-04   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  8.845261e-08  5.673692e-07  2.185301e-06  7.444148e-07  2.017738e-04   \n",
       "778  3.591797e-08  4.240455e-07  1.551022e-06  1.363590e-07  1.432590e-05   \n",
       "779  8.832764e-07  4.378901e-06  1.285613e-06  8.524936e-06  4.783742e-04   \n",
       "780  2.805889e-05  3.204079e-04  2.950669e-07  4.707098e-04  5.880752e-07   \n",
       "781  8.976022e-08  8.475187e-07  1.047357e-06  1.614747e-07  2.474583e-05   \n",
       "\n",
       "               49            50            51            52            53  \\\n",
       "0    2.174506e-06  3.665759e-08  4.478506e-04  4.650679e-04  1.211206e-05   \n",
       "1    2.324675e-03  6.748711e-04  7.841913e-06  1.797475e-08  9.208373e-05   \n",
       "2    4.264420e-03  3.207233e-06  4.141561e-05  2.466323e-05  1.434178e-06   \n",
       "3    8.310549e-03  6.330538e-04  1.585062e-04  5.253386e-06  2.855355e-05   \n",
       "4    9.502537e-04  5.820632e-04  5.014890e-06  8.111192e-07  1.425431e-05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  3.374573e-04  1.702022e-03  2.183509e-07  3.351120e-08  2.855817e-06   \n",
       "778  1.126615e-04  8.413609e-05  4.325434e-07  7.853837e-09  1.182301e-05   \n",
       "779  2.380906e-03  1.889450e-04  1.027952e-05  3.110814e-07  1.133624e-05   \n",
       "780  8.497389e-07  5.535009e-10  4.641344e-07  5.805668e-09  7.169170e-09   \n",
       "781  1.472671e-04  8.589283e-05  1.351910e-07  1.652482e-08  2.854900e-06   \n",
       "\n",
       "               54            55            56            57            58  \\\n",
       "0    2.320302e-06  1.255611e-07  2.459125e-07  8.899527e-10  6.392489e-03   \n",
       "1    1.928369e-04  1.234607e-04  4.037772e-06  1.639472e-04  8.937501e-06   \n",
       "2    8.685702e-04  1.100743e-06  3.044588e-03  6.567472e-08  8.927088e-04   \n",
       "3    1.086101e-04  3.191976e-05  3.284602e-06  5.761672e-05  2.509627e-05   \n",
       "4    2.082707e-06  2.616074e-06  4.458506e-07  2.302143e-03  8.492467e-05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  4.701814e-07  2.122393e-07  2.414436e-07  1.602291e-02  2.339808e-05   \n",
       "778  1.135056e-06  1.329223e-06  6.008780e-07  3.952625e-03  5.511012e-06   \n",
       "779  1.826907e-05  1.181306e-05  3.889178e-07  7.185910e-05  1.804710e-05   \n",
       "780  2.958758e-05  7.718703e-08  1.964780e-06  6.251173e-12  1.060830e-07   \n",
       "781  9.722719e-07  3.358905e-07  1.054960e-07  2.254390e-03  9.878531e-05   \n",
       "\n",
       "               59            60  \n",
       "0    1.507664e-05  3.401015e-06  \n",
       "1    2.063025e-05  1.227229e-05  \n",
       "2    1.204468e-02  2.228847e-03  \n",
       "3    5.781790e-06  7.223898e-03  \n",
       "4    2.439178e-06  3.807932e-03  \n",
       "..            ...           ...  \n",
       "777  2.259146e-06  5.595793e-03  \n",
       "778  6.515145e-07  3.573783e-05  \n",
       "779  1.360694e-06  7.549015e-04  \n",
       "780  1.251617e-05  4.916669e-09  \n",
       "781  9.046755e-07  1.539940e-04  \n",
       "\n",
       "[782 rows x 62 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('./data/sample_submission.csv')\n",
    "submission.iloc[:,1:]=pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('sub_kfold_stratified_10_adam_fft_0.5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
